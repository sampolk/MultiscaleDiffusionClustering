%{
This script loads and analyzes eleven benchmark datasets from the 
University of California, Irvine Machine Learning Repository. We compare 
the Multiscale Learning by Unsupervised Nonlinear Diffusion (M-LUND) 
algorithm against the following algorithms:

    1. Multiscale Markov Stability (MMS)

       Liu, Zijing, and Mauricio Barahona. "Graph-based data clustering via 
       multiscale community detection." Applied Network Science 5.1 (2020):
       1-20.

    2. Hierarchical Spectral Clustering (HSC)

       Azran, Arik, and Zoubin Ghahramani. "Spectral methods for automatic 
       multiscale data clustering." 2006 IEEE Computer Society Conference 
       on Computer Vision and Pattern Recognition (CVPR'06). Vol. 1. IEEE, 
       2006.

    3. Single-Linkage Clustering (SLC)

       Gower, John C., and Gavin JS Ross. "Minimum spanning trees and 
       single linkage cluster analysis." Journal of the Royal Statistical 
       Society: Series C (Applied Statistics) 18.1 (1969): 54-64.

    4. K-Means Clustering

       MacQueen, James. "Some methods for classification and analysis of 
       multivariate observations." Proceedings of the fifth Berkeley 
       symposium on mathematical statistics and probability. Vol. 1. 
       No. 14. 1967.

            - We only compare against K-means in the fixed-K setting.

All diffusion-based algorithms were evaluated using the same graph & time 
samples. This script generates two tables storing performance:

    - In T3, we evaluate algorithms when the number of clusters K is fixed 
      to be the number of clusters in the ground truth labels. The
      normalized mutual information between the outputted clustering and
      the ground truth labels is used as the performance measure.

    - In T4, we evaluate multiscale algorithms by comparing the optimal
      clustering these methods generate against the ground truth labels using
      normalized mutual information.

To compare against MMS clustering, the following two toolboxes must be
downloaded and added to your path. If not, MMS performances are left NaN.

    - Graph-Based Clustering (https://github.com/barahona-research-group/GraphBasedClustering)
    - Partition Stability    (https://wwwf.imperial.ac.uk/~mpbara/Partition_Stability/)

The tables generated by this script appear in the following paper: 

     - Murphy, James M and Polk, Sam L. "A Multiscale Environment for 
       Learning By Diffusion." In Preparation (2021).

(c) Sam L. Polk: samuel.polk@tufts.edu

%}
%% Comparisons 
datasets = {'control_chart.mat', 'glass.mat', 'iris.mat', 'IS.mat', 'parkinsons.mat', 'Seed.mat', 'WBCD.mat', 'Wine.mat', 'yeast.mat', 'breasttissue.mat', 'vertebra.mat'};

T3 = zeros(11,5);
T4 = zeros(11,4);
for data_id = 1:11
    
    % ------------------ Load Data and Graph Structure --------------------
    % Load Data & Hyperparameters
    file_name = datasets{data_id};
    directory_name = erase(file_name, '.mat');
    load(file_name)
    load(strcat(directory_name, 'HyperparametersFinal.mat')) % loads hyperparameters   
    n = size(X,1);
    D = squareform(pdist(X));
    
    % Convert ground truth labels into proper format.
    unique_K = unique(GT);
    K_GT = length(unique_K);
    for k = 1:K_GT
        GT(GT == unique_K(k)) = k;
    end
     
    % Extract graph and time steps
    Graph = extract_graph(X, Hyperparameters);

    T = full(ceil(log( log(Hyperparameters.Tau*min(Graph.StationaryDist)/2)/log(Graph.EigenVals(2)) )/log(Hyperparameters.Beta)));
    TimeSamples = [0, Hyperparameters.Beta.^(0:T)];   
    
    disp(strcat(directory_name, ' loaded'))
    
    % ------------------------------ M-LUND -------------------------------
    
    % Multiscale
    p = KDE(X,Hyperparameters,D);
    Clusterings = M_LUND(X, Hyperparameters, Graph, p);
    nmi_temp = nmi(Clusterings.Labels(:,Clusterings.TotalVI.Minimizer_Idx), GT);
    T4(data_id,1) = nmi_temp;
    
    % Single Scale
    nmi_LUND = zeros(T+2,1);
    for i = 1:T+2
        [C,~,~] = LearningbyUnsupervisedNonlinearDiffusion(X, TimeSamples(i), Graph, p, K_GT);  
        nmi_LUND(i) = nmi( C, GT);
    end
    T3(data_id,1) = max(nmi_LUND);
    
    disp(strcat(directory_name, ' M-LUND run complete'))  
    
    % ----------------------------- SL-LUND -------------------------------
    
    t_idx = find(and(Clusterings.K>1, Clusterings.K<n/2), 1, 'first');
    t = Clusterings.TimeSamples(t_idx);
    T3(data_id, 6) = nmi(GT, LearningbyUnsupervisedNonlinearDiffusion(X, t, Graph, p, K_GT));

    [C_Orig, C_MS] = SL_LUND(X, Clusterings, flag);
    
    % Construct Diffusion Distances
    DiffusionMap = zeros(n,Clusterings.Hyperparameters.NEigs);
    for k = 1:size(DiffusionMap,2)
        DiffusionMap(:,k) = ((Clusterings.Graph.EigenVals(k)).^t).*Clusterings.Graph.EigenVecs(:,k);
    end
    DiffusionDistance = squareform(pdist(DiffusionMap));
    
    DtIn = NaN*zeros(size(C_MS,2)-1,1);
    DtBtw = NaN*zeros(size(C_MS,2)-1,1);    
    for j = 1:size(C_MS,2)-1
        C = C_MS(:,j);
        
        candidates = zeros(length(unique(C)),2);
        for k = 1:length(unique(C))
            
            candidates(k,1) = max(DiffusionDistance(C==k,C==k), [],'all');
            candidates(k,2) = min(DiffusionDistance(C==k,~(C==k)), [],'all');            
        
        end
        DtIn(j) = max(candidates(:,1));
        DtBtw(j) = min(candidates(:,2));
        
    end
    
    [~,j] = min(DtIn./DtBtw);
    T4(data_id, 5) = nmi(C_MS(:,j), GT);
    

    % ------------------------------- MMS ---------------------------------
    
    try 
        % Multiscale
        [~, K_MMS, ~, C_MMS] = stability(Graph.W,TimeSamples,'full');
        [~,~, t] = totalVI_minimization(C_MMS, K_MMS);
        T4(data_id,2) = nmi(C_MMS(:,t), GT);

        % Single scale
        t = find(K_MMS == K_GT,1, 'first');
        if ~isempty(t)
            T3(data_id,2) = nmi(C_MMS(:,t), GT);
        else
            T3(data_id,2) = NaN;
        end
        disp(strcat(directory_name, ' MMS run complete'))
    catch
        T3(data_id,2) = NaN;
        T4(data_id,2) = NaN;
    end
    
    % ------------------------------- HSC ---------------------------------
    

    NEigs = Hyperparameters.NEigs;
    Hyperparameters.NEigs = max(Hyperparameters.NEigs, K_GT);
    % Extract graph and time steps
    Graph = extract_graph(X, Hyperparameters);

    % Multiscale
    T_max = max(TimeSamples);
    [C_HSC, K_HSC, t_vals_HSC, Alpha_HSC, Beta_HSC] = HierearchicalSpectralClustering(Graph, T_max);
    
    % Here, we use the equivalent definition of total VI: weighting the VI 
    % between each clustering by the log-length of the interval it was 
    % extracted: |J_l| = log_Beta(Alpha_l*T_max). 
    
    stability_weights = (log(Alpha_HSC*T_max)/log(Hyperparameters.Beta));
    [~,~, t] = totalVI_minimization(C_HSC, K_HSC, stability_weights);
    T4(data_id,3) = nmi(C_HSC(:,t), GT);
    
    % Single Scale
    T3(data_id,3) = nmi(SpectralClustering(K_GT, Graph), GT);

    disp(strcat(directory_name, ' HSC run complete'))
    
    % ------------------------------- SLC ---------------------------------
    
    % Multiscale
    Z_SLC = linkage(X,'single');
    C_SLC  = zeros(n);
    NMIs_SLC = zeros(length(Z_SLC),1);
    Quality = zeros(length(Z_SLC),1);
    
    for K = 1:n
        C = cluster(Z_SLC,'MaxClust',K);
        
        if K >1
            cands_in = zeros(K,1);
            cands_btw = zeros(K,1);
            for k = 1:K
                cands_in(k)  = max(D(C==k,  (C==k)), [],'all');
                cands_btw(k) = min(D(C==k, ~(C==k)), [],'all');
            end
            Quality(K) = max(cands_in)/min(cands_btw);
        else
            Quality(K) = NaN;
        end
        C_SLC(:,K) = C;
    end
    idx = 2:n/2; % Only consider nontrivial clusterings
    [~,K] = min(Quality(idx));
    T4(data_id,4) = nmi(C_SLC(:,idx(K)), GT);
    
    % Single-Scale
    T3(data_id,4) = nmi(cluster(Z_SLC,'MaxClust',K_GT), GT);
    
    disp(strcat(directory_name, ' SLC run complete'))
    
    % ----------------------------- K-Means -------------------------------
    T3(data_id,5) = nmi(kmeans(X, K_GT), GT);
    disp(strcat(directory_name, ' K-Means run complete'))
    
    disp(strcat(directory_name, ' analysis complete. ',num2str(floor(data_id*100/11)), '% done.'))
    
    save(strcat(directory_name, 'HyperparametersFinal.mat'), 'Hyperparameters')
    
end
%% 
if sum(or(isnan(T3(:,2)), T3(:,2)==0)) == 11  
    % MMS has not been added to path and is excluded from statistical 
    % comparisons
    idx_include = 1:11;
else
    % Exclude indices where MMS returns no K = K_GT clustering from averages
    % and statistical testing
    idx_include = find(~isnan(T3(:,2)));
end

% statistical testing on Table 3
p_vals3 = NaN*zeros(1,5);
t_vals3 = NaN*zeros(1,5);
for alg_id = setdiff(1:5,2)
    [~,p, ~, stats] = ttest(T3(idx_include,1), T3(idx_include,alg_id));
    p_vals3(alg_id) = p;
    t_vals3(alg_id) = stats.tstat;
end

% Convert Table 3 into presentable format
T3 = [T3; mean(T3(idx_include,:)); [0,p_vals3]; [Inf, t_vals3]];
cols = {'M-LUND', 'MMS', 'HSC', 'SLC', 'K-Means', 'LUND'};
rows = datasets';
rows{12} = 'Average';
rows{13} = 'p-value';
rows{14} = 'Test Statistic';
T3 = array2table(T3, 'VariableNames', cols, 'RowNames', rows);


% statistical testing on Table 4
p_vals4 = ones(1,4);
t_vals4 = ones(1,4);
for alg_id = setdiff(1:5,2)
    [~,p, ~, stats] = ttest(T4(:,1), T4(:,alg_id));
    p_vals4(alg_id) = p;
    t_vals4(alg_id) = stats.tstat;
end

% Convert Table 4 into presentable format
T4 = [T4; mean(T4); [p_vals4]; [ t_vals4]];
cols = {'M-LUND', 'MMS', 'HSC', 'SLC', 'SL-LUND'};
rows = datasets';
rows{12} = 'Average';
rows{13} = 'p-value';
rows{14} = 'Test Statistic';
T4 = array2table(T4, 'VariableNames', cols, 'RowNames', rows);


% Display results in the command window
clc
disp('========================================================================================')
disp('Fixed-Scale Performance Comparisons (Table 3):')
disp(T3)
disp('========================================================================================')
disp('Multiscale Performance Comparisons (Table 4):')
disp(T4)
disp('========================================================================================')
